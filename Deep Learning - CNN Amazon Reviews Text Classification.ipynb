{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the performance of a convolutional neural network (CNN) model using three different sets of text vector embeddings on a binary text classification problem. Using a dataset of Amazon reviews, I compare a CNN that trains its own embeddings against pretrained vector embeddings from GloVe and FastText. The self-trained embeddings result in the best model validation performance. I then use Keras Tuner to perform hyperparameter tuning of the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Preparing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WDMvmja9LOBa"
   },
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpslTGZRcHFu",
    "outputId": "f26c4a8b-59aa-4236-f6e5-208d3ff4f385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mount drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HOG2wVAqM_WD"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Xiang Zhang's Amazon Reviews Polarity dataset\n",
    "# Available for download here: https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz\n",
    "\n",
    "# Unpack tar file\n",
    "tar = tarfile.open('gdrive/My Drive/Colab Notebooks/Data/amazon_review_polarity_csv.tar.gz')\n",
    "tar_train = tar.extractfile('amazon_review_polarity_csv/train.csv')\n",
    "tar_test = tar.extractfile('amazon_review_polarity_csv/test.csv')\n",
    "\n",
    "# Read csv\n",
    "full_train = pd.read_csv(tar_train, header=None, names=['label', 'title', 'text'])\n",
    "full_eval = pd.read_csv(tar_test, header=None, names=['label', 'title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yQZnxQx7Jw_",
    "outputId": "12db492b-fdea-454e-fd91-88646a445f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600000 entries, 0 to 3599999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   label   int64 \n",
      " 1   title   object\n",
      " 2   text    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 82.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Look at the data\n",
    "full_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sLpKUuWD7P4X",
    "outputId": "d97cde7f-81b6-4ba2-887f-70ce8cdcb43b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  ...                                               text\n",
       "0      2  ...  This sound track was beautiful! It paints the ...\n",
       "1      2  ...  I'm reading a lot of reviews saying that this ...\n",
       "2      2  ...  This soundtrack is my favorite music of all ti...\n",
       "3      2  ...  I truly like this soundtrack and I enjoy video...\n",
       "4      2  ...  If you've played the game, you know how divine...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dk7w2WY4FNNn",
    "outputId": "1904aa52-5c1f-437b-8b87-3ed0221c1de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   label   400000 non-null  int64 \n",
      " 1   title   399990 non-null  object\n",
      " 2   text    400000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "full_eval.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kq7qFEgrFPQV",
    "outputId": "f7e6cbff-7fc5-401e-c9db-a34b814fbecb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Great CD</td>\n",
       "      <td>My lovely Pat has one of the GREAT voices of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>Despite the fact that I have only played a sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Batteries died within a year ...</td>\n",
       "      <td>I bought this charger in Jul 2003 and it worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>works fine, but Maha Energy is better</td>\n",
       "      <td>Check out Maha Energy's website. Their Powerex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the non-audiophile</td>\n",
       "      <td>Reviewed quite a bit of the combo players and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  ...                                               text\n",
       "0      2  ...  My lovely Pat has one of the GREAT voices of h...\n",
       "1      2  ...  Despite the fact that I have only played a sma...\n",
       "2      1  ...  I bought this charger in Jul 2003 and it worke...\n",
       "3      2  ...  Check out Maha Energy's website. Their Powerex...\n",
       "4      2  ...  Reviewed quite a bit of the combo players and ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kfU6Pfz7VK9",
    "outputId": "510607a6-62ef-4620-dea5-86058928d208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1800000\n",
       "1    1800000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes are evenly balanced\n",
    "full_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lzJHJmd5FTEt",
    "outputId": "2e71299f-9d82-4aa1-e4df-df1131f97464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    200000\n",
       "1    200000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_eval['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "7K06ZAq-SqHJ",
    "outputId": "7fd51b30-9457-4152-c875-4829179e5976"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at two training examples\n",
    "full_train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "ri2_lgZfT6Lx",
    "outputId": "ecc54184-33ab-42fd-da65-da80c86a6971"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\""
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bqffehlUHQ1",
    "outputId": "c01165cb-fa2a-433a-f422-c5bdc55182d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at two training labels\n",
    "full_train['label'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tJPnYWbQURsf"
   },
   "outputs": [],
   "source": [
    "# Recode labels as binary\n",
    "full_train['label'] = full_train['label'] - 1\n",
    "full_eval['label'] = full_eval['label'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCeZJFR-XFHF",
    "outputId": "b9bf1281-d68f-471e-c6d0-a31f428c941b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1800000\n",
       "0    1800000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMTPXoPIFi1W",
    "outputId": "ef346ffa-443a-4dff-98a0-bb36f8311205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    200000\n",
       "0    200000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_eval['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "l2jJz8xKPfBd"
   },
   "outputs": [],
   "source": [
    "# Full dataset is 3.6 million rows and takes prohibitively long to tokenize and model \n",
    "# Take a 10% sample - still 360,000 rows!\n",
    "small_train = full_train.sample(frac=.1, random_state=42).reset_index(drop=True)\n",
    "small_eval = full_eval.sample(frac=.1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eqVfxrN5Fyf-"
   },
   "outputs": [],
   "source": [
    "# Save copies of prepared training and eval data for easy recall\n",
    "X_train, X_eval, y_train, y_eval = small_train['text'], small_eval['text'], small_train['label'], small_eval['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7ksBoAHmU7C"
   },
   "source": [
    "# Convolutional Neural Network (CNN) Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RXl8mb0zuSCX"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Training\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# Vector-space embedding\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 400\n",
    "oov_token = 'OOV'\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "# Convolutional layer architecture\n",
    "n_conv = 256 # filters\n",
    "k_conv = 3 # kernel length\n",
    "\n",
    "# Dense layer architecture\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dp11fNwEaoZg"
   },
   "outputs": [],
   "source": [
    "# Preprocess text \n",
    "\n",
    "# Reload prepared raw data\n",
    "X_train, X_eval, y_train, y_eval = small_train['text'], small_eval['text'], small_train['label'], small_eval['label']\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = Tokenizer(num_words=n_unique_words, oov_token=oov_token)\n",
    "\n",
    "# Fit on training\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert training and eval data to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_eval = tokenizer.texts_to_sequences(X_eval)\n",
    "\n",
    "# Padding\n",
    "X_train = pad_sequences(X_train, maxlen=max_review_length, \n",
    "                        padding=pad_type, truncating=trunc_type, value=0)\n",
    "X_eval = pad_sequences(X_eval, maxlen=max_review_length, \n",
    "                        padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw8m_OY5vz8v",
    "outputId": "dcd56263-68b5-4cfc-f9cc-eb9756b577c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 64)           320000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 256)          49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 435,457\n",
      "Trainable params: 435,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Vector-space embedding\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Dense layer\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gM9x5dFVy4NK",
    "outputId": "6d0cdbda-cde1-4f27-8ac6-f6a8e1e3981d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2813/2813 [==============================] - 97s 23ms/step - loss: 0.2749 - accuracy: 0.8830 - val_loss: 0.2273 - val_accuracy: 0.9077\n",
      "Epoch 2/4\n",
      "2813/2813 [==============================] - 66s 24ms/step - loss: 0.2115 - accuracy: 0.9163 - val_loss: 0.2205 - val_accuracy: 0.9117\n",
      "Epoch 3/4\n",
      "2813/2813 [==============================] - 66s 23ms/step - loss: 0.1893 - accuracy: 0.9262 - val_loss: 0.2212 - val_accuracy: 0.9119\n",
      "Epoch 4/4\n",
      "2813/2813 [==============================] - 66s 23ms/step - loss: 0.1717 - accuracy: 0.9337 - val_loss: 0.2226 - val_accuracy: 0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbd883467d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model and evaluate\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOwhr4IU_aO3"
   },
   "source": [
    "# Result: CNN best validation accuracy: 0.9119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDYisQC1tQSv"
   },
   "source": [
    "# CNN with Pretrained embeddings (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yK4SIEwW6tgz"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters are the same as the first CNN model with these 2 changes\n",
    "\n",
    "n_dim = 100 # To match 100D GloVe embeddings\n",
    "n_unique_words = len(tokenizer.word_index) + 1 # +1 is for padding token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGojS4np3aub"
   },
   "source": [
    "## Prepare the GloVe embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkC-GGgHtbEa",
    "outputId": "078a1b00-bc0c-420f-b8e4-6e266390bbeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-25 18:34:41--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-07-25 18:34:41--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-07-25 18:34:42--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.28MB/s    in 2m 40s  \n",
      "\n",
      "2021-07-25 18:37:22 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the GloVe embeddings\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuXj6RIgLOBn",
    "outputId": "350a7b02-5ece-4b15-a9a9-230ac979b8a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hapGaPC9sLH2"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((n_unique_words, n_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mKfugCQTsPeI"
   },
   "outputs": [],
   "source": [
    "# Define GloVe embedding layer\n",
    "glove_embeddings = Embedding(n_unique_words, \n",
    "                             n_dim, \n",
    "                             weights=[embedding_matrix], \n",
    "                             input_length=max_review_length, \n",
    "                             trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8a_bh883edl"
   },
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l08OjN_c3zJ9",
    "outputId": "093474a8-4d9b-4cc0-9ca1-7f81967c3fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 400, 100)          26350500  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 400, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 398, 256)          77056     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 26,493,605\n",
      "Trainable params: 143,105\n",
      "Non-trainable params: 26,350,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Vector-space embedding\n",
    "model.add(glove_embeddings) # Pretrained GloVe embeddings\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Dense layer\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMZhOiug8xgJ",
    "outputId": "8d04eec4-5ac7-4163-af4b-427346a96598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2813/2813 [==============================] - 51s 18ms/step - loss: 0.3630 - accuracy: 0.8367 - val_loss: 0.2844 - val_accuracy: 0.8772\n",
      "Epoch 2/4\n",
      "2813/2813 [==============================] - 50s 18ms/step - loss: 0.2986 - accuracy: 0.8723 - val_loss: 0.2682 - val_accuracy: 0.8853\n",
      "Epoch 3/4\n",
      "2813/2813 [==============================] - 50s 18ms/step - loss: 0.2810 - accuracy: 0.8813 - val_loss: 0.2653 - val_accuracy: 0.8885\n",
      "Epoch 4/4\n",
      "2813/2813 [==============================] - 50s 18ms/step - loss: 0.2711 - accuracy: 0.8860 - val_loss: 0.2582 - val_accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbd70211f90>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model and evaluate\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBqrDIHRARp9"
   },
   "source": [
    "# Result: CNN with GloVe embeddings best validation accuracy: 0.8914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsRWNEyqaGsy"
   },
   "source": [
    "# CNN with Pretrained FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "EAgJN2tOZzu9"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters are the same as the first CNN model with these 2 changes\n",
    "\n",
    "n_dim = 300 # To match 300D FastText embeddings\n",
    "n_unique_words = len(tokenizer.word_index) + 1 # +1 is for padding token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk9B9YQqahih"
   },
   "source": [
    "## Prepare FastText embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXqqdhPMWwoC",
    "outputId": "bb6779cc-ea10-4311-dda4-5ff63003f639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-25 20:35:45--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 681808098 (650M) [application/zip]\n",
      "Saving to: ‘wiki-news-300d-1M.vec.zip.2’\n",
      "\n",
      "wiki-news-300d-1M.v 100%[===================>] 650.22M  57.6MB/s    in 12s     \n",
      "\n",
      "2021-07-25 20:35:57 (53.3 MB/s) - ‘wiki-news-300d-1M.vec.zip.2’ saved [681808098/681808098]\n",
      "\n",
      "replace wiki-news-300d-1M.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "y\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
    "!unzip -q wiki-news-300d-1M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLYqvMtDW51j",
    "outputId": "29b91877-2ba4-48bb-9940-19c5e0f86839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 999995 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load the whole FastText embedding into memory\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('wiki-news-300d-1M.vec')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZQMYCJIkZP1Z"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((n_unique_words, n_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DVLYHiUZaXTo"
   },
   "outputs": [],
   "source": [
    "# Define GloVe embedding layer\n",
    "fasttext_embeddings = Embedding(n_unique_words, \n",
    "                             n_dim, \n",
    "                             weights=[embedding_matrix], \n",
    "                             input_length=max_review_length, \n",
    "                             trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ6xuS4faqQC"
   },
   "source": [
    "# Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLoLcGJ6aSE9",
    "outputId": "c4afce83-f81c-41f8-a165-7e4cbff003b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 300)          79051200  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 400, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 256)          230656    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 79,347,905\n",
      "Trainable params: 296,705\n",
      "Non-trainable params: 79,051,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Vector-space embedding\n",
    "model.add(fasttext_embeddings) # Pretrained FastText embeddings\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Dense layer\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehzv4rBfa94n",
    "outputId": "bf05ad49-5dd2-4e99-8611-1522af7fb724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2813/2813 [==============================] - 127s 34ms/step - loss: 0.2895 - accuracy: 0.8764 - val_loss: 0.2416 - val_accuracy: 0.9006\n",
      "Epoch 2/4\n",
      "2813/2813 [==============================] - 95s 34ms/step - loss: 0.2328 - accuracy: 0.9050 - val_loss: 0.2301 - val_accuracy: 0.9056\n",
      "Epoch 3/4\n",
      "2813/2813 [==============================] - 96s 34ms/step - loss: 0.2154 - accuracy: 0.9131 - val_loss: 0.2276 - val_accuracy: 0.9067\n",
      "Epoch 4/4\n",
      "2813/2813 [==============================] - 97s 34ms/step - loss: 0.2024 - accuracy: 0.9186 - val_loss: 0.2203 - val_accuracy: 0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73fb361190>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model and evaluate\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HxKKE8ScsoC"
   },
   "source": [
    "# Result: CNN with FastText best validation accuracy: 0.9111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bN1so9zAeZd"
   },
   "source": [
    "# Tune Hyperparameters with Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMqeCiIOjolN",
    "outputId": "ce7a5a9b-20f6-48ed-92f1-698eaebf53af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |███▍                            | 10 kB 24.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 20 kB 31.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 30 kB 21.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 40 kB 17.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 51 kB 7.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 61 kB 8.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 71 kB 8.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 81 kB 9.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 92 kB 9.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 96 kB 4.0 MB/s \n",
      "\u001b[?25h  Building wheel for kt-legacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Install keras tuner and import\n",
    "!pip install keras-tuner -q\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZA2rtlPek3Zt"
   },
   "outputs": [],
   "source": [
    "# Default hyperparameters\n",
    "\n",
    "# Training\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# Vector-space embedding\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 400\n",
    "oov_token = 'OOV'\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "# Convolutional layer architecture\n",
    "n_conv = 256 # filters\n",
    "k_conv = 3 # kernel length\n",
    "\n",
    "# Dense layer architecture\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "dUm58Vuds52D"
   },
   "outputs": [],
   "source": [
    "# Create model function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Embedding layer\n",
    "    model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
    "    model.add(SpatialDropout1D(drop_embed))\n",
    "\n",
    "    # Convolutional layer\n",
    "    model.add(Conv1D(filters=hp.Choice('n_filters', values=[64, 128, 256]),\n",
    "                     kernel_size=k_conv, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    # Dense layer\n",
    "    model.add(Dense(units=hp.Choice(\"n_dense\", values=[128, 256, 512]), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Choice(\"dense_dropout_rate\", values=[0.0, 0.2, 0.5])))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "GUPAm5FELOBo"
   },
   "outputs": [],
   "source": [
    "# Create the tuner\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Mc1fJbtjlj6",
    "outputId": "72a78be5-5777-45ee-fbb4-3e55958b9c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "n_filters (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
      "n_dense (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64, 128, 256, 512], 'ordered': True}\n",
      "dense_dropout_rate (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.2, 0.5], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqVhw1A3nf6B",
    "outputId": "e33b069b-c610-4779-a6f5-3f03b87f421a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 08m 21s]\n",
      "val_loss: 0.22162976115942\n",
      "\n",
      "Best val_loss So Far: 0.22162976115942\n",
      "Total elapsed time: 00h 23m 48s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=2, verbose=1, validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXfMnkqMqN3M",
    "outputId": "198fecc6-034f-4dd5-d352-a796d4521ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters: 256\n",
      "n_dense: 64\n",
      "dense_dropout_rate: 0.2\n",
      "Score: 0.22162976115942\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters: 128\n",
      "n_dense: 128\n",
      "dense_dropout_rate: 0.5\n",
      "Score: 0.2265392318367958\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_filters: 64\n",
      "n_dense: 64\n",
      "dense_dropout_rate: 0.5\n",
      "Score: 0.2386171743273735\n"
     ]
    }
   ],
   "source": [
    "# Best set of hyperparameters\n",
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Learning Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
